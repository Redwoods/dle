# Notebooks for DLe

- [chap03: 머신러닝 Top10](https://yozm.wishket.com/magazine/detail/1931/)
> [gradient Boosting => XGBoost, LightGBM, Catboost](https://m.blog.naver.com/jaehong7719/221950378451)
> XGBoost, LightGBM, Catboost는 모두 gradient boosting 기반의 머신러닝 알고리즘입니다. 각각의 특징과 차이점은 다음과 같습니다  

- XGBoost는 eXtreme Gradient Boosting의 약자로, 빠른 속도와 높은 성능을 자랑하는 알고리즘입니다. 병렬 처리, 정규화, 가지치기 등의 기능을 제공합니다. 분류와 회귀 문제에 모두 적용할 수 있습니다.  
- LightGBM은 Light Gradient Boosting Machine의 약자로, XGBoost보다 더 빠르고 메모리 효율적인 알고리즘입니다. 리프 중심 트리 분할(leaf-wise tree split) 방식을 사용하여 깊은 트리를 생성합니다. 대용량 데이터에 적합하며, 범주형 변수를 자동으로 인코딩하는 기능도 있습니다.  
- Catboost는 Categorical Boosting의 약자로, 범주형 변수를 잘 처리할 수 있는 알고리즘입니다. 타겟 인코딩(target encoding) 방식을 사용하여 범주형 변수를 수치형 변수로 변환합니다. 과적합 방지를 위한 정규화와 학습률 조절 등의 기능도 있습니다.  
어떤 알고리즘을 선택할지는 데이터의 특성과 목적에 따라 달라질 수 있습니다. 성능 비교를 위해 각각의 알고리즘을 적용해보시는 것이 좋습니다.
---

