{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/Redwoods/dle/blob/main/project/cifar10/cifar10_DL1_CNN_best_model.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "rswfCVLZ-QW0"
      },
      "source": [
        "- Conv2D + FCN\n",
        "    * Conv2D : 2차원 합성곱 필터링 + 풀링(Pooling)\n",
        "    - > 2차원 필터로 영상을 대표하는 특징을 추출\n",
        "    * FCN : 1차원 완전연결신경망\n",
        "    - > Conv2D에서 추출된 대표 특징들을 이용하여 FCN으로 최종 학습 완료\n",
        "\n",
        "***\n",
        "- ## Traget: Find the best model\n",
        "***\n",
        "\n",
        "![cnn_c4f5.png](https://raw.githubusercontent.com/Redwoods/Py/master//pdm2020/my-note/py-tensorflow/images/cnn_c4f5.png)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ISueys4bNHd1"
      },
      "source": [
        "### CIFAR-10 Dataset (CIFAR: Canadian Institute For Advanced Research)\n",
        "> https://www.cs.toronto.edu/~kriz/cifar.html\n",
        "\n",
        "- (50000, 32, 32, 3), train\n",
        "- (10000, 32, 32, 3), test\n",
        "- color photographs of objects from 10 classes, such as frogs, birds, cats, ships, etc\n",
        "> class names\n",
        "> - ['airplane', 'automobile', 'bird', 'cat', 'deer', 'dog', 'frog', 'horse', 'ship', 'truck']\n",
        "\n",
        "- 참고 문헌  \n",
        "\n",
        "> https://becominghuman.ai/cifar-10-image-classification-fd2ace47c5e8  \n",
        "\n",
        "> https://becominghuman.ai/convolutional-neural-networks-cnns-convnets-for-visual-recognition-cae879a70f1a\n",
        "\n",
        "> https://towardsdatascience.com/cifar-10-image-classification-in-tensorflow-5b501f7dc77c"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "1yhvkxS_HhpK"
      },
      "source": [
        "## Search the best model of C2F2\n",
        "- callback\n",
        "    - Early stopping\n",
        "    - model checkpoint"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "8GgGzPXPVyfa"
      },
      "outputs": [],
      "source": [
        "import numpy as np\n",
        "import tensorflow as tf\n",
        "from tensorflow import keras\n",
        "import pandas as pd\n",
        "import matplotlib.pyplot as plt\n",
        "# %matplotlib inline\n",
        "\n",
        "tf.random.set_seed(0)\n",
        "\n",
        "print(tf.__version__)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "nMZqMpIvIlwf"
      },
      "outputs": [],
      "source": [
        "# import TF2 submodules\n",
        "from tensorflow.keras import layers, models, callbacks"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "-0IOOUM14Jk1"
      },
      "source": [
        "## **데이터 로딩, 정규화**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "N1ogJ7I64Fz-"
      },
      "outputs": [],
      "source": [
        "from keras.datasets import cifar10\n",
        "\n",
        "(X_train0, y_train0), (X_test0, y_test0) = cifar10.load_data()\n",
        "\n",
        "# Reshape\n",
        "# X_train = X_train0.reshape(60000,28,28,1)\n",
        "# X_test = X_test0.reshape(10000,28,28,1)\n",
        "\n",
        "# Normalization\n",
        "X_train, X_test = X_train0/255.0, X_test0/255.0 # 정규화\n",
        "\n",
        "print(\"X_train={0}\".format(X_train.shape))\n",
        "print(\"y_train={0}\".format(y_train0.shape)) \n",
        "print(\"X_test={0}\".format(X_test.shape))\n",
        "print(\"y_test={0}\".format(y_test0.shape))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "F46-QZqJHiQ6"
      },
      "outputs": [],
      "source": [
        "# One-Hot-Encoding\n",
        "# Use function to_categorical() to do One-Hot-Encoding\n",
        "# tf.keras.utils.to_categorical\n",
        "from tensorflow.keras.utils import to_categorical\n",
        "\n",
        "y_train = to_categorical(y_train0, 10)\n",
        "y_test = to_categorical(y_test0, 10)\n",
        "y_train.shape,y_test.shape"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "eZ3OfP5PkEkL"
      },
      "outputs": [],
      "source": [
        "# y_train0.shape vs. y_train.shape\n",
        "y_train0.shape, y_train.shape"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "5z7SozStigmF"
      },
      "source": [
        "### Display images in CIFAR-10\n",
        "- one random image\n",
        "- 10 representative images"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "IK7XT3XoirSL"
      },
      "outputs": [],
      "source": [
        "# Code here!\n",
        "# display one random image from the training set:\n",
        "class_names =  ['airplane', 'automobile', 'bird', 'cat', 'deer', 'dog', 'frog', 'horse', 'ship', 'truck']\n",
        "\n",
        "idx = np.random.randint(0, X_train0.shape[0])\n",
        "print(idx)\n",
        "image = X_train0[idx]\n",
        "plt.figure(figsize=(2,2))\n",
        "plt.imshow(image) #, cmap=plt.get_cmap('gray'))\n",
        "plt.title(class_names[y_train0[idx][0]])\n",
        "plt.xticks([])\n",
        "plt.yticks([])\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "LzhD5pcukau7"
      },
      "outputs": [],
      "source": [
        "fig = plt.figure(figsize=(10,6))\n",
        "num0_9 = np.unique(y_train0, return_index=True)[1]\n",
        "images = X_train[num0_9]\n",
        "for i in range(10):\n",
        "    plt.subplot(2, 5, i+1)\n",
        "    # num0_9 = X_train0[y_train0 == i]\n",
        "    \n",
        "    # print(num0_9.shape)\n",
        "    # plt.imshow(num0_9[0]) \n",
        "    plt.imshow(images[i])\n",
        "    plt.title(class_names[i])\n",
        "    plt.xticks([])\n",
        "    plt.yticks([])"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "55DYVfFXi0WR"
      },
      "source": [
        "# Design CNN"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "iPcLIcUCcsiG"
      },
      "source": [
        "### import models, layers, callbacks\n",
        "- models: Sequential\n",
        "- layers: Conv2D, MaxPool2D, Flatten\n",
        "- callbacks: ModelCheckpoint, EarlyStopping"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "NzqMC4Xtc3ZE"
      },
      "outputs": [],
      "source": [
        "from keras.models import Sequential\n",
        "from keras.layers import Conv2D, MaxPool2D, Flatten\n",
        "from keras.callbacks import ModelCheckpoint, EarlyStopping"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "7Z6DJJUCei-s"
      },
      "source": [
        "## **CNN2 + FCN2**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "hTLkuGeYsVrs"
      },
      "outputs": [],
      "source": [
        "# Random number seed\n",
        "np.random.seed(1234)\n",
        "tf.random.set_seed(1234)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "pV3NFglM7P65"
      },
      "outputs": [],
      "source": [
        "c2f2 = keras.models.Sequential([ \n",
        "    Conv2D(input_shape=(32,32,3), filters= 32, kernel_size=(3,3), strides=(1,1), padding='same', activation='relu'),\n",
        "    MaxPool2D(pool_size=(2,2), strides=(2,2)), \n",
        "    Conv2D(filters= 64, kernel_size=(3,3), strides=(1,1), padding='same', activation='relu'),\n",
        "    MaxPool2D(pool_size=(2,2), strides=(2,2)),\n",
        "    Flatten(), \n",
        "    keras.layers.Dense(128, activation='relu'),  \n",
        "    keras.layers.Dropout(0.25), \n",
        "    keras.layers.Dense(10, activation='softmax')\n",
        "])\n",
        "\n",
        "c2f2.compile(optimizer='adam',\n",
        "              loss='categorical_crossentropy',\n",
        "              metrics=['accuracy']) "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "OGtCiKy57YkR"
      },
      "outputs": [],
      "source": [
        "# 모델 구조 요약 - summary(), plot_model()\n",
        "c2f2.summary()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "HdyQrc3sNMJG"
      },
      "outputs": [],
      "source": [
        "keras.utils.plot_model(c2f2, show_shapes=True)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "5HIlfgyBNvr4"
      },
      "outputs": [],
      "source": [
        "# !pip install visualkeras"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "wfKtN2TdO5Pc"
      },
      "outputs": [],
      "source": [
        "!fc-list"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "-sDntLaNNnNw"
      },
      "outputs": [],
      "source": [
        "# 모델 구조 시각화 - visualkareas.layered_view()\n",
        "import visualkeras\n",
        "from PIL import ImageFont\n",
        "# font = ImageFont.truetype(\"Humor-Sans.ttf\", 24)  # Linux\n",
        "# font = ImageFont.truetype(\"arial.ttf\", 24)  # windows 10/11\n",
        "visualkeras.layered_view(c2f2, \n",
        "                         to_file='./c2f2.png', \n",
        "                         legend=True, spacing=80,  # font=font, \n",
        "                         scale_xy=5, scale_z=1, one_dim_orientation='x')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "zw_pQPBdJmU8"
      },
      "outputs": [],
      "source": [
        "cp_callback = callbacks.ModelCheckpoint(filepath=\"./cifar10_c2f2_best_weights.{epoch:03d}-{val_accuracy:.4f}.hdf5\", \n",
        "                              monitor='val_accuracy', verbose=0, save_best_only=True)\n",
        "es_callback = callbacks.EarlyStopping(monitor='val_accuracy', \n",
        "                            mode='max', verbose=1, patience=5)    # patience=10, 25, 50"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "94GWWQt-7eRS"
      },
      "outputs": [],
      "source": [
        "BATCH_SIZE = 50  # cifar10\n",
        "hist = c2f2.fit(X_train, y_train, epochs = 500 , batch_size = BATCH_SIZE, \n",
        "         callbacks=[cp_callback, es_callback], \n",
        "         validation_data=(X_test,y_test))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "0-7is2U49A6Z"
      },
      "outputs": [],
      "source": [
        "c2f2.evaluate(X_test, y_test, batch_size = BATCH_SIZE)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "x9EQ2Z_c2gYL"
      },
      "outputs": [],
      "source": [
        "# More graphs of loss and accuracy\n",
        "history_dict = hist.history\n",
        "loss = history_dict['loss']\n",
        "val_loss = history_dict['val_loss']\n",
        "\n",
        "epochs = range(1, len(loss) + 1)\n",
        "\n",
        "plt.figure(figsize=(14, 4))\n",
        "\n",
        "plt.subplot(1,2,1)\n",
        "plt.plot(epochs, loss, 'go-', label='Training Loss')\n",
        "plt.plot(epochs, val_loss, 'bd', label='Validation Loss')\n",
        "plt.plot(np.argmin(np.array(val_loss))+1,val_loss[np.argmin(np.array(val_loss))], 'r*', ms=12)\n",
        "plt.title('Training and Validation Loss, min: ' + str(np.round(val_loss[np.argmin(np.array(val_loss))],4)))\n",
        "plt.xlabel('Epochs')\n",
        "plt.ylabel('Loss')\n",
        "plt.legend()\n",
        "\n",
        "acc = history_dict['accuracy']\n",
        "val_acc = history_dict['val_accuracy']\n",
        "\n",
        "epochs = range(1, len(loss) + 1)\n",
        "\n",
        "plt.subplot(1,2,2)\n",
        "plt.plot(epochs, acc, 'go-', label='Training Accuracy') #, c='blue')\n",
        "plt.plot(epochs, val_acc, 'bd', label='Validation Accuracy') #, c='red')\n",
        "plt.plot(np.argmax(np.array(val_acc))+1,val_acc[np.argmax(np.array(val_acc))], 'r*', ms=12)\n",
        "plt.title('Training and Validation Accuracy, max: ' + str(np.round(val_acc[np.argmax(np.array(val_acc))],4)))\n",
        "plt.xlabel('Epochs')\n",
        "plt.ylabel('Accuracy')\n",
        "plt.legend()\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ubm5q_onsVrv"
      },
      "source": [
        "## Best c2f2 model of cifar10\n",
        "- cifar10_c2f2_best_weights.012-0.7226.hdf5\n",
        "- cifar10_c2f2_best_weights.013-0.7183.hdf5"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "SUJxRQtafihM"
      },
      "source": [
        "## **CNN2 + FCN3**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "9Pzdv-CDsVrv"
      },
      "outputs": [],
      "source": [
        "# Random number seed\n",
        "np.random.seed(1234)\n",
        "tf.random.set_seed(1234)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Nl5CyAymAB34"
      },
      "outputs": [],
      "source": [
        "c2f3 = keras.models.Sequential([ \n",
        "    Conv2D(input_shape=(32,32,3), filters= 32, kernel_size=(3,3), strides=(1,1), padding='same', activation='relu'),\n",
        "    MaxPool2D(pool_size=(2,2), strides=(2,2)), \n",
        "    Conv2D(filters= 64, kernel_size=(3,3), strides=(1,1), padding='same', activation='relu'),\n",
        "    MaxPool2D(pool_size=(2,2), strides=(2,2)),\n",
        "    Flatten(), \n",
        "    keras.layers.Dense(128, activation='relu'),  \n",
        "    keras.layers.Dropout(0.25), \n",
        "    keras.layers.Dense(64, activation='relu'),  \n",
        "    keras.layers.Dropout(0.25), \n",
        "    keras.layers.Dense(10, activation='softmax')\n",
        "])\n",
        "\n",
        "c2f3.compile(optimizer='adam',\n",
        "              loss='categorical_crossentropy',\n",
        "              metrics=['accuracy']) "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "gYxuGW_2ANL8"
      },
      "outputs": [],
      "source": [
        "c2f3.summary()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "2n5Bsn3UQgCu"
      },
      "outputs": [],
      "source": [
        "# 모델 구조 시각화 - visualkareas.layered_view()\n",
        "import visualkeras\n",
        "from PIL import ImageFont\n",
        "# font = ImageFont.truetype(\"Humor-Sans.ttf\", 24)  # Linux\n",
        "# font = ImageFont.truetype(\"arial.ttf\", 24)  # windows 10/11\n",
        "visualkeras.layered_view(c2f3, \n",
        "                         to_file='./c2f3.png', \n",
        "                         legend=True, spacing=80,  # font=font, \n",
        "                         scale_xy=5, scale_z=1, one_dim_orientation='x')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "KMsTuhO2x61z"
      },
      "outputs": [],
      "source": [
        "cp_callback = callbacks.ModelCheckpoint(filepath=\"./cifar10_c2f3_best_weights.{epoch:03d}-{val_accuracy:.4f}.hdf5\", \n",
        "                              monitor='val_accuracy', verbose=0, save_best_only=True)\n",
        "es_callback = callbacks.EarlyStopping(monitor='val_accuracy', \n",
        "                            mode='max', verbose=1, patience=5)    # patience=10, 25, 50"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "lO1of4AOAQlV"
      },
      "outputs": [],
      "source": [
        "hist = c2f3.fit(X_train, y_train, epochs=500, batch_size = BATCH_SIZE, \n",
        "         callbacks=[cp_callback, es_callback], \n",
        "         validation_data=(X_test,y_test))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "W-eIxCasDBil"
      },
      "outputs": [],
      "source": [
        " c2f3.evaluate(X_test, y_test, batch_size = BATCH_SIZE)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Xuw_jhKQsVrx"
      },
      "outputs": [],
      "source": [
        "# More graphs of loss and accuracy\n",
        "history_dict = hist.history\n",
        "loss = history_dict['loss']\n",
        "val_loss = history_dict['val_loss']\n",
        "\n",
        "epochs = range(1, len(loss) + 1)\n",
        "\n",
        "plt.figure(figsize=(14, 4))\n",
        "\n",
        "plt.subplot(1,2,1)\n",
        "plt.plot(epochs, loss, 'go-', label='Training Loss')\n",
        "plt.plot(epochs, val_loss, 'bd', label='Validation Loss')\n",
        "plt.plot(np.argmin(np.array(val_loss))+1,val_loss[np.argmin(np.array(val_loss))], 'r*', ms=12)\n",
        "plt.title('Training and Validation Loss, min: ' + str(np.round(val_loss[np.argmin(np.array(val_loss))],4)))\n",
        "plt.xlabel('Epochs')\n",
        "plt.ylabel('Loss')\n",
        "plt.legend()\n",
        "\n",
        "acc = history_dict['accuracy']\n",
        "val_acc = history_dict['val_accuracy']\n",
        "\n",
        "epochs = range(1, len(loss) + 1)\n",
        "\n",
        "plt.subplot(1,2,2)\n",
        "plt.plot(epochs, acc, 'go-', label='Training Accuracy') #, c='blue')\n",
        "plt.plot(epochs, val_acc, 'bd', label='Validation Accuracy') #, c='red')\n",
        "plt.plot(np.argmax(np.array(val_acc))+1,val_acc[np.argmax(np.array(val_acc))], 'r*', ms=12)\n",
        "plt.title('Training and Validation Accuracy, max: ' + str(np.round(val_acc[np.argmax(np.array(val_acc))],4)))\n",
        "plt.xlabel('Epochs')\n",
        "plt.ylabel('Accuracy')\n",
        "plt.legend()\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "J316fZ9GsVrx"
      },
      "source": [
        "## Best c2f3 model of cifar10\n",
        "- cifar10_c2f3_best_weights.013-0.7161.hdf5\n",
        "- cifar10_c2f3_best_weights.011-0.7155.hdf5"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "5XYSVtC-DVsz"
      },
      "source": [
        "# **[DIY] Hidden layer에 따른 정확도**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "OiCc_UO2rGmp"
      },
      "outputs": [],
      "source": [
        "score1=c2f2.evaluate(X_test, y_test, batch_size = BATCH_SIZE)\n",
        "score2=c2f3.evaluate(X_test, y_test, batch_size = BATCH_SIZE)\n",
        "losses = [score1[0],score2[0]]\n",
        "accuracies= [score1[1],score2[1]]\n",
        "losses,accuracies"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "vZv6a2aVRw9j"
      },
      "outputs": [],
      "source": [
        "x = np.arange(2)\n",
        "cnns = ['C2F2','C2F3']\n",
        "\n",
        "plt.bar(x, accuracies)\n",
        "plt.xticks(x, cnns)\n",
        "plt.ylim((.5,1.0))\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "63oPbpPejqOj"
      },
      "source": [
        "## Complex model\n",
        "- C4F5 model\n",
        "\n",
        "![cnn_c4f5.png](https://raw.githubusercontent.com/Redwoods/Py/master//pdm2020/my-note/py-tensorflow/images/cnn_c4f5.png)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "D6BA9Ct8SPuN"
      },
      "outputs": [],
      "source": [
        "# Random number seed\n",
        "np.random.seed(1234)\n",
        "tf.random.set_seed(1234)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "kSN8pq8DkQ6B"
      },
      "outputs": [],
      "source": [
        "c4f5 = keras.models.Sequential([ \n",
        "    Conv2D(input_shape=(32,32,3), filters= 64, kernel_size=(3,3),strides=(1,1), padding='same',activation='relu'),\n",
        "    MaxPool2D(pool_size=(2,2), strides=(2,2)), \n",
        "    Conv2D(filters= 128, kernel_size=(3,3), strides=(1,1), padding='same',activation='relu'),\n",
        "    MaxPool2D(pool_size=(2,2), strides=(2,2)),\n",
        "    Conv2D(filters= 256, kernel_size=(3,3), strides=(1,1), padding='same',activation='relu'),\n",
        "    MaxPool2D(pool_size=(2,2), strides=(2,2)),\n",
        "    Conv2D(filters= 512, kernel_size=(3,3), strides=(1,1), padding='same',activation='relu'),\n",
        "    MaxPool2D(pool_size=(2,2), strides=(2,2)),\n",
        "    Flatten(), \n",
        "    keras.layers.Dense(128, activation='relu'),  \n",
        "    keras.layers.Dropout(0.25), \n",
        "    keras.layers.Dense(256, activation='relu'),  \n",
        "    keras.layers.Dropout(0.25), \n",
        "    keras.layers.Dense(512, activation='relu'),  \n",
        "    keras.layers.Dropout(0.25), \n",
        "    keras.layers.Dense(1024, activation='relu'),  \n",
        "    keras.layers.Dropout(0.25), \n",
        "    keras.layers.Dense(10, activation='softmax')\n",
        "])\n",
        "\n",
        "c4f5.compile(optimizer='adam',\n",
        "              loss='categorical_crossentropy',\n",
        "              metrics=['accuracy']) "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "k7qWzpLRkQ6C"
      },
      "outputs": [],
      "source": [
        "c4f5.summary()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "M-ztnlkuRjFh"
      },
      "outputs": [],
      "source": [
        "# 모델 구조 시각화 - visualkareas.layered_view()\n",
        "import visualkeras\n",
        "from PIL import ImageFont\n",
        "# font = ImageFont.truetype(\"Humor-Sans.ttf\", 24)  # Linux\n",
        "# font = ImageFont.truetype(\"arial.ttf\", 24)  # windows 10/11\n",
        "visualkeras.layered_view(c4f5, \n",
        "                         to_file='./c4f5.png', \n",
        "                         legend=True, spacing=80,  # font=font, \n",
        "                         scale_xy=5, scale_z=1, one_dim_orientation='x')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "-pKJWy-2kQ6C"
      },
      "outputs": [],
      "source": [
        "cp_callback = callbacks.ModelCheckpoint(filepath=\"./cifar10_c4f5_best_weights.{epoch:03d}-{val_accuracy:.4f}.hdf5\", \n",
        "                              monitor='val_accuracy', verbose=0, save_best_only=True)\n",
        "es_callback = callbacks.EarlyStopping(monitor='val_accuracy', \n",
        "                            mode='max', verbose=1, patience=5)    # patience=10, 25, 50"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "wKdgr9EskQ6C"
      },
      "outputs": [],
      "source": [
        "hist = c4f5.fit(X_train, y_train, epochs=500, batch_size = BATCH_SIZE, \n",
        "         callbacks=[cp_callback, es_callback], \n",
        "         validation_data=(X_test,y_test))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "jfwYHBexkQ6D"
      },
      "outputs": [],
      "source": [
        " c4f5.evaluate(X_test, y_test, batch_size = BATCH_SIZE)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "3Ub3qGnjs4EI"
      },
      "source": [
        "## Graph of loss and accuracy\n",
        "- model: C4f5"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "N_zYFwbwsVr0"
      },
      "outputs": [],
      "source": [
        "# More graphs of loss and accuracy\n",
        "history_dict = hist.history\n",
        "loss = history_dict['loss']\n",
        "val_loss = history_dict['val_loss']\n",
        "\n",
        "epochs = range(1, len(loss) + 1)\n",
        "\n",
        "plt.figure(figsize=(14, 4))\n",
        "\n",
        "plt.subplot(1,2,1)\n",
        "plt.plot(epochs, loss, 'go-', label='Training Loss')\n",
        "plt.plot(epochs, val_loss, 'bd', label='Validation Loss')\n",
        "plt.plot(np.argmin(np.array(val_loss))+1,val_loss[np.argmin(np.array(val_loss))], 'r*', ms=12)\n",
        "plt.title('Training and Validation Loss, min: ' + str(np.round(val_loss[np.argmin(np.array(val_loss))],4)))\n",
        "plt.xlabel('Epochs')\n",
        "plt.ylabel('Loss')\n",
        "plt.legend()\n",
        "\n",
        "acc = history_dict['accuracy']\n",
        "val_acc = history_dict['val_accuracy']\n",
        "\n",
        "epochs = range(1, len(loss) + 1)\n",
        "\n",
        "plt.subplot(1,2,2)\n",
        "plt.plot(epochs, acc, 'go-', label='Training Accuracy') #, c='blue')\n",
        "plt.plot(epochs, val_acc, 'bd', label='Validation Accuracy') #, c='red')\n",
        "plt.plot(np.argmax(np.array(val_acc))+1,val_acc[np.argmax(np.array(val_acc))], 'r*', ms=12)\n",
        "plt.title('Training and Validation Accuracy, max: ' + str(np.round(val_acc[np.argmax(np.array(val_acc))],4)))\n",
        "plt.xlabel('Epochs')\n",
        "plt.ylabel('Accuracy')\n",
        "plt.legend()\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "97G08isfsVr0"
      },
      "source": [
        "## Best c4f5 model of cifar10\n",
        "- cifar10_c4f5_best_weights.010-0.7446.hdf5\n",
        "- cifar10_c4f5_best_weights.012-0.7493.hdf5"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "gBPKMI4y3fsa"
      },
      "source": [
        "## 모형의 저장\n",
        "\n",
        "- 트레이닝이 끝난 모형은 save 메서드로 가중치와 함께 hdf5 형식으로 저장\n",
        "- load 명령으로 불러 사용"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "r7-KSSrCsVr0"
      },
      "source": [
        "## Best model\n",
        "- cifar10_c4f5_best_weights.012-0.7493.hdf5"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "b7-ysIVy3fse"
      },
      "outputs": [],
      "source": [
        "from keras.models import load_model\n",
        "\n",
        "model_best = load_model('cifar10_c4f5_best_weights.012-0.7438.hdf5')\n",
        "model_best.evaluate(X_test, y_test, batch_size=BATCH_SIZE)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "KF3UzDJotZrh"
      },
      "source": [
        "## Confusion matrix"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "RV1IaOyeu6Em"
      },
      "outputs": [],
      "source": [
        "from sklearn.metrics import confusion_matrix\n",
        "import seaborn as sns"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Bxs1eC-cuO0Y"
      },
      "outputs": [],
      "source": [
        "predictions = model_best.predict(X_test)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "nZch1JFSufoR"
      },
      "outputs": [],
      "source": [
        "predictions0 = np.argmax(predictions, axis=1)\n",
        "predictions0.shape"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "hiPMQeYXt12l"
      },
      "outputs": [],
      "source": [
        "cm = confusion_matrix(y_test0, predictions0)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "YITaGwYjvatc"
      },
      "outputs": [],
      "source": [
        "class_names = ['airplane', 'automobile', 'bird', 'cat', 'deer', 'dog', 'frog', 'horse', 'ship', 'truck']"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "2qGHMNU3u8ut"
      },
      "outputs": [],
      "source": [
        "plt.figure(figsize=(9,9))\n",
        "sns.heatmap(cm, cbar=False, xticklabels=class_names, yticklabels=class_names, fmt='d', annot=True, cmap=plt.cm.coolwarm)\n",
        "plt.xlabel('Predicted')\n",
        "plt.ylabel('Actual')\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "m6ckhbERsVr2"
      },
      "source": [
        "---"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ySvdVr1CHExd"
      },
      "outputs": [],
      "source": [
        "#\n",
        "# New method to plot confusion_matrix\n",
        "#\n",
        "from sklearn.metrics import confusion_matrix, ConfusionMatrixDisplay\n",
        "\n",
        "# y_pred = mlp.predict(X_test)\n",
        "cm = confusion_matrix(y_test0, predictions0)\n",
        "disp = ConfusionMatrixDisplay(confusion_matrix=cm) #, display_labels=mlp.classes_)\n",
        "disp.plot(cmap='Blues')\n",
        "\n",
        "plt.savefig('confusion_matrix.pdf')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "SQ3M6vRVXG78"
      },
      "source": [
        "## cifar10 모델 학습\n",
        "> https://gruuuuu.github.io/machine-learning/cifar10-cnn/#"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "0n2PfCMBh2ju"
      },
      "source": [
        "# State of current scores of cifar-10\n",
        "\n",
        "> https://paperswithcode.com/sota/image-classification-on-cifar-10"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "7abyx_2n0_7d"
      },
      "source": [
        "## Transfer learning on cifar-10\n",
        "\n",
        "- https://medium.com/@andrew.dabydeen/transfer-learning-using-resnet50-and-cifar-10-6242ed4b4245\n",
        "\n",
        "- https://medium.com/swlh/comparative-analysis-of-cifar-10-image-classification-transfer-learning-vs-user-defined-cnns-e673685d925e\n",
        "\n",
        "- https://medium.com/swlh/hands-on-the-cifar-10-dataset-with-transfer-learning-2e768fd6c318\n",
        "\n",
        "- https://medium.com/analytics-vidhya/the-transfer-learning-experience-with-vgg16-and-cifar-10-dataset-9b25b306a23f"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "xmWCauBEsVr3"
      },
      "source": [
        "---"
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "provenance": [],
      "gpuType": "T4",
      "include_colab_link": true
    },
    "gpuClass": "standard",
    "interpreter": {
      "hash": "3834ce636a3ba6c6c2bd8b9b527c48eede78c367f849f6cce666ea7f1d26e2fb"
    },
    "kernelspec": {
      "display_name": "Python 3 (Spyder)",
      "language": "python3",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.9.13"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}